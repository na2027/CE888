# -*- coding: utf-8 -*-
"""Copy of bank_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BMLaG8XqLVhXhNKNBhwkmUIHi4ckUOEu
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import preprocessing
from sklearn import model_selection
from sklearn import metrics
from sklearn.preprocessing import LabelEncoder
# %matplotlib inline

import warnings

warnings.filterwarnings('ignore')

df=pd.read_csv("bank-additional-full.csv",sep=';')
df=df.drop(['duration'],axis=1)
df.head()



"""Exploratory Analysis:
Categorical Variables:

"""

# find categorical variables

categorcial_variables = [var for var in df.columns if df[var].dtype=='O']

print('There are {} categorical variables\n'.format(len(categorcial_variables)))

print('The categorical variables are :', categorcial_variables)

for col in categorcial_variables:
    plt.figure(figsize=(10,4))
    sns.barplot(df[col].value_counts().values, df[col].value_counts().index)
    plt.title(col)
    plt.tight_layout()

df[categorical].isnull().sum()

# let's do One Hot Encoding of Location variable
# get k-1 dummy variables after One Hot Encoding 
# preview the dataset with head() method

pd.get_dummies(df.job, drop_first=True).head()

pd.get_dummies(df.marital, drop_first=True).head()

pd.get_dummies(df.education, drop_first=True).head()

pd.get_dummies(df.default, drop_first=True).head()

pd.get_dummies(df.housing, drop_first=True).head()

pd.get_dummies(df.loan, drop_first=True).head()

pd.get_dummies(df.contact, drop_first=True).head()

pd.get_dummies(df.month, drop_first=True).head()

pd.get_dummies(df.day_of_week, drop_first=True).head()

print(df.job.value_counts())
sns.countplot(y='job', data=df)

print(df.marital.value_counts())
sns.countplot(x='marital', data=df)

print(df.education.value_counts())
sns.countplot(x='education', data=df)

"""LabelEncoder"""

y_valus ={'yes' : 1, 'no' : 0}
df['y'] = df['y'].map(lambda x: y_valus[x])
df['y'].value_counts()

y = df['y']

df.drop(['y'], axis = 1, inplace = True)
df.head()

df.shape

df.drop(['contact','month','day_of_week','default','pdays',],axis=1,inplace=True)

df.shape

#splitting the data 
x_train, lbl_x_test, y_train, lbl_y_test = model_selection.train_test_split(df, y, test_size=0.2, random_state=50)
lbl_x_train, lbl_x_cv, lbl_y_train, lbl_y_cv = model_selection.train_test_split(x_train, y_train, test_size=0.2)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import GridSearchCV

dept = [1, 5, 10]
n_estimators =  [20, 40, 60, 80, 100]


param_grid={'n_estimators':n_estimators , 'max_depth':dept}
clf = RandomForestClassifier()
model = GridSearchCV(clf,param_grid,scoring='roc_auc',n_jobs=-1,cv=3)
model.fit(lbl_x_train,lbl_y_train)
print("optimal n_estimators",model.best_estimator_.n_estimators)
print("optimal max_depth",model.best_estimator_.max_depth)

